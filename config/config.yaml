# dataset_name: cifar100

device: "cuda"             # or "cpu"
num_samples: 5000
dataset_name: "clane9/imagenet-100" #"cifar100" #
split: "validation" # train test val validation
model_id: "ViT-B/16"
visualize: False

# annotations: /home/utn/firi22ka/Desktop/jenga/Adaptive-Tokenization/new_src/clane9/imagenet-100_500_0.3_1758275065.0351467.jsonl

# only to collect data
keep_pct: 1 # 0 to 1 

# data related
annotation_path: "/var/lit2425/jenga/Adaptive-Tokenization/new_src/clane9/imagenet-100_1500_1758042869.1699746.jsonl" # path to annotation file
# val_ratio: 0.1
data_split_ratio: [0.7, 0.15, 0.15] # [train, val, test] split ratios
num_classes: 196 # toal number of patches of size 16*16 = 196  (14*14)

# model_checkpoint: "/var/lit2425/jenga/Adaptive-Tokenization/new_src/cp_1221/checkpoint_best.pt" #path to best model checkpoit for evaluation 
# GA can optionally optimize the keep percentage (number of patches kept).
optimize_keep: true
min_keep_pct: 0.1  # lower bound on keep ratio when optimizing
max_keep_pct: 0.95  # upper bound on keep ratio when optimizing
keep_penalty: 0.3  # penalty strength for keeping more patches (trade-off)



# Training
batch_size: 2
epochs: 1
lr: 0.0001
img_size: 224
num_workers: 2
device: cuda
save_dir: ./checkpoints_01
seed: 42




# Note: split is fixed at 70/15/15 in code
# val_split is unused but kept for CLI compatibility
# val_split: 0.15

# Prediction export
predictions_jsonl: ./checkpoints01/predictions.jsonl
pred_thresh: 0.5

#testing 
model_checkpoint: "/var/lit2425/jenga/Adaptive-Tokenization/new_src/cp_1221/checkpoint_best.pt" 
